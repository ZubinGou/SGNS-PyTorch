{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T11:32:18.111976Z",
     "start_time": "2021-03-08T11:32:17.794087Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "import pprint\n",
    "import tqdm\n",
    "\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T02:34:51.871196Z",
     "start_time": "2021-03-06T02:34:51.858070Z"
    }
   },
   "source": [
    "## Train by gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T11:32:21.828103Z",
     "start_time": "2021-03-08T11:32:18.998738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_records': 1701, 'record_format': 'list of str (tokens)', 'file_size': 33182058, 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/text8/__init__.py', 'license': 'not found', 'description': 'First 100,000,000 bytes of plain text from Wikipedia. Used for testing purposes; see wiki-english-* for proper full Wikipedia datasets.', 'checksum': '68799af40b6bda07dfa47a32612e5364', 'file_name': 'text8.gz', 'read_more': ['http://mattmahoney.net/dc/textdata.html'], 'parts': 1}\n"
     ]
    }
   ],
   "source": [
    "print(api.info(\"text8\"))\n",
    "dataset = api.load(\"text8\")\n",
    "\n",
    "with open(\"dataset/text8.txt\", \"w\") as f:\n",
    "    for data in dataset:\n",
    "        f.write(\" \".join(data) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取text8部分：\n",
    "```sh\n",
    "$ head -i 300 text8.txt > text8_300.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T11:43:04.421986Z",
     "start_time": "2021-03-08T11:41:55.542837Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset = open(\"dataset/text8_300.txt\").read()\n",
    "dataset = api.load(\"text8\")\n",
    "model = Word2Vec(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T11:43:46.600013Z",
     "start_time": "2021-03-08T11:43:46.243064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.627785768466384\n",
      "0.31882345872691664\n",
      "0.252110218276648\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.evaluate_word_pairs(datapath('wordsim353.tsv'))[1][0])\n",
    "print(model.wv.evaluate_word_pairs(\"word2vec/rw/rw_clean.txt\")[1][0])\n",
    "print(model.wv.evaluate_word_pairs(datapath('simlex999.txt'))[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train by word2vec DIY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T12:18:06.175335Z",
     "start_time": "2021-03-08T12:16:49.317700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "len data: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/code/SGNS-PyTorch/word2vec/data_reader.py:63: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  discards = np.sqrt(t / self.word_frequency) + (t / self.word_frequency)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1, batch=    0: sp=-0.000 -0.003  pair/sec = 3274.42 loss=0.139\n",
      "epoch= 1, batch=  100: sp=0.002 0.012  pair/sec = 10666.56 loss=1.367\n",
      "epoch= 1, batch=  200: sp=-0.014 -0.005  pair/sec = 10722.20 loss=1.277\n",
      "epoch= 1, batch=  300: sp=0.083 0.036  pair/sec = 10744.17 loss=1.253\n",
      "epoch= 1, batch=  400: sp=0.037 0.029  pair/sec = 10706.12 loss=1.194\n",
      "epoch= 1, batch=  500: sp=0.069 0.052  pair/sec = 10644.72 loss=1.115\n",
      "epoch= 1, batch=  600: sp=0.038 0.022  pair/sec = 10651.15 loss=1.121\n",
      "epoch= 1, batch=  700: sp=0.020 0.042  pair/sec = 10652.40 loss=1.094\n",
      "epoch= 1, batch=  800: sp=0.042 0.028  pair/sec = 10636.31 loss=1.096\n",
      "epoch= 1, batch=  900: sp=0.055 0.044  pair/sec = 10656.22 loss=1.144\n",
      "epoch= 1, batch= 1000: sp=0.053 0.050  pair/sec = 10639.80 loss=1.072\n",
      "epoch= 1, batch= 1100: sp=0.075 0.054  pair/sec = 10656.68 loss=1.046\n",
      "epoch= 1, batch= 1200: sp=0.061 0.027  pair/sec = 10640.13 loss=1.080\n",
      "epoch= 1, batch= 1300: sp=0.043 0.027  pair/sec = 10660.63 loss=1.050\n",
      "epoch= 1, batch= 1400: sp=0.043 0.036  pair/sec = 10665.67 loss=1.061\n",
      "epoch= 1, batch= 1500: sp=0.030 0.010  pair/sec = 10685.54 loss=1.088\n",
      "epoch= 1, batch= 1600: sp=0.024 0.009  pair/sec = 10666.34 loss=1.047\n",
      "\n",
      "epoch= 2, batch=    0: sp=0.078 0.029  pair/sec = 3487.40 loss=0.105\n",
      "epoch= 2, batch=  100: sp=0.088 0.058  pair/sec = 10644.03 loss=1.000\n",
      "epoch= 2, batch=  200: sp=0.082 0.055  pair/sec = 10652.64 loss=0.931\n",
      "epoch= 2, batch=  300: sp=0.093 0.056  pair/sec = 10648.90 loss=0.981\n",
      "epoch= 2, batch=  400: sp=0.108 0.060  pair/sec = 10646.67 loss=0.956\n",
      "epoch= 2, batch=  500: sp=0.118 0.064  pair/sec = 10677.31 loss=0.950\n",
      "epoch= 2, batch=  600: sp=0.110 0.057  pair/sec = 10668.05 loss=0.945\n",
      "epoch= 2, batch=  700: sp=0.097 0.059  pair/sec = 10673.45 loss=0.949\n",
      "epoch= 2, batch=  800: sp=0.083 0.054  pair/sec = 10669.09 loss=0.957\n",
      "epoch= 2, batch=  900: sp=0.088 0.053  pair/sec = 10673.42 loss=0.981\n",
      "epoch= 2, batch= 1000: sp=0.101 0.062  pair/sec = 10672.50 loss=0.959\n",
      "epoch= 2, batch= 1100: sp=0.099 0.058  pair/sec = 10687.66 loss=0.945\n",
      "epoch= 2, batch= 1200: sp=0.088 0.046  pair/sec = 10652.91 loss=0.968\n",
      "epoch= 2, batch= 1300: sp=0.071 0.050  pair/sec = 10674.29 loss=0.950\n",
      "epoch= 2, batch= 1400: sp=0.072 0.063  pair/sec = 10672.98 loss=0.949\n",
      "epoch= 2, batch= 1500: sp=0.064 0.053  pair/sec = 10682.77 loss=1.005\n",
      "epoch= 2, batch= 1600: sp=0.076 0.059  pair/sec = 10691.10 loss=0.980\n",
      "\n",
      "epoch= 3, batch=    0: sp=0.107 0.075  pair/sec = 3399.13 loss=0.098\n",
      "epoch= 3, batch=  100: sp=0.110 0.094  pair/sec = 10645.37 loss=0.934\n",
      "epoch= 3, batch=  200: sp=0.118 0.099  pair/sec = 10684.87 loss=0.878\n",
      "epoch= 3, batch=  300: sp=0.128 0.095  pair/sec = 10655.51 loss=0.922\n",
      "epoch= 3, batch=  400: sp=0.133 0.097  pair/sec = 10508.81 loss=0.908\n",
      "epoch= 3, batch=  500: sp=0.134 0.095  pair/sec = 10504.41 loss=0.901\n",
      "epoch= 3, batch=  600: sp=0.130 0.092  pair/sec = 10502.72 loss=0.901\n",
      "epoch= 3, batch=  700: sp=0.122 0.091  pair/sec = 10499.07 loss=0.914\n",
      "epoch= 3, batch=  800: sp=0.112 0.091  pair/sec = 10491.04 loss=0.915\n",
      "epoch= 3, batch=  900: sp=0.093 0.079  pair/sec = 10715.39 loss=0.943\n",
      "epoch= 3, batch= 1000: sp=0.081 0.075  pair/sec = 10752.73 loss=0.926\n",
      "epoch= 3, batch= 1100: sp=0.067 0.066  pair/sec = 10747.05 loss=0.914\n",
      "epoch= 3, batch= 1200: sp=0.048 0.050  pair/sec = 10747.38 loss=0.933\n",
      "epoch= 3, batch= 1300: sp=0.040 0.053  pair/sec = 10755.13 loss=0.916\n",
      "epoch= 3, batch= 1400: sp=0.033 0.058  pair/sec = 10756.80 loss=0.918\n",
      "epoch= 3, batch= 1500: sp=0.019 0.050  pair/sec = 10761.00 loss=0.971\n",
      "epoch= 3, batch= 1600: sp=0.042 0.057  pair/sec = 10758.68 loss=0.949\n",
      "\n",
      "epoch= 4, batch=    0: sp=0.066 0.070  pair/sec = 3431.58 loss=0.095\n",
      "epoch= 4, batch=  100: sp=0.075 0.091  pair/sec = 10681.92 loss=0.907\n",
      "epoch= 4, batch=  200: sp=0.073 0.086  pair/sec = 10756.93 loss=0.858\n",
      "epoch= 4, batch=  300: sp=0.066 0.084  pair/sec = 10752.20 loss=0.900\n",
      "epoch= 4, batch=  400: sp=0.068 0.083  pair/sec = 10752.23 loss=0.888\n",
      "epoch= 4, batch=  500: sp=0.085 0.089  pair/sec = 10753.70 loss=0.881\n",
      "epoch= 4, batch=  600: sp=0.081 0.087  pair/sec = 10713.85 loss=0.883\n",
      "epoch= 4, batch=  700: sp=0.073 0.084  pair/sec = 10748.06 loss=0.897\n",
      "epoch= 4, batch=  800: sp=0.082 0.096  pair/sec = 10719.54 loss=0.896\n",
      "epoch= 4, batch=  900: sp=0.088 0.102  pair/sec = 10744.66 loss=0.926\n",
      "epoch= 4, batch= 1000: sp=0.117 0.115  pair/sec = 10760.75 loss=0.912\n",
      "epoch= 4, batch= 1100: sp=0.125 0.120  pair/sec = 10758.11 loss=0.896\n",
      "epoch= 4, batch= 1200: sp=0.117 0.111  pair/sec = 10752.67 loss=0.918\n",
      "epoch= 4, batch= 1300: sp=0.110 0.118  pair/sec = 10753.37 loss=0.896\n",
      "epoch= 4, batch= 1400: sp=0.104 0.122  pair/sec = 10744.84 loss=0.901\n",
      "epoch= 4, batch= 1500: sp=0.096 0.118  pair/sec = 10755.39 loss=0.956\n",
      "epoch= 4, batch= 1600: sp=0.100 0.115  pair/sec = 10754.87 loss=0.936\n",
      "\n",
      "epoch= 5, batch=    0: sp=0.106 0.117  pair/sec = 3432.43 loss=0.095\n",
      "epoch= 5, batch=  100: sp=0.114 0.136  pair/sec = 10710.70 loss=0.895\n",
      "epoch= 5, batch=  200: sp=0.123 0.140  pair/sec = 10758.60 loss=0.850\n",
      "epoch= 5, batch=  300: sp=0.119 0.135  pair/sec = 10753.61 loss=0.892\n",
      "epoch= 5, batch=  400: sp=0.119 0.134  pair/sec = 10750.03 loss=0.879\n",
      "epoch= 5, batch=  500: sp=0.128 0.134  pair/sec = 10744.26 loss=0.874\n",
      "epoch= 5, batch=  600: sp=0.130 0.132  pair/sec = 10740.07 loss=0.872\n",
      "epoch= 5, batch=  700: sp=0.131 0.130  pair/sec = 10750.71 loss=0.886\n",
      "epoch= 5, batch=  800: sp=0.142 0.140  pair/sec = 10750.68 loss=0.889\n",
      "epoch= 5, batch=  900: sp=0.139 0.139  pair/sec = 10719.08 loss=0.919\n",
      "epoch= 5, batch= 1000: sp=0.146 0.140  pair/sec = 10719.48 loss=0.901\n",
      "epoch= 5, batch= 1100: sp=0.137 0.138  pair/sec = 10730.89 loss=0.884\n",
      "epoch= 5, batch= 1200: sp=0.135 0.131  pair/sec = 10731.37 loss=0.910\n",
      "epoch= 5, batch= 1300: sp=0.126 0.134  pair/sec = 10632.19 loss=0.885\n",
      "epoch= 5, batch= 1400: sp=0.118 0.136  pair/sec = 10676.49 loss=0.891\n",
      "epoch= 5, batch= 1500: sp=0.119 0.134  pair/sec = 10673.90 loss=0.947\n",
      "epoch= 5, batch= 1600: sp=0.117 0.133  pair/sec = 10679.11 loss=0.927\n",
      "\n",
      "epoch= 6, batch=    0: sp=0.114 0.129  pair/sec = 3213.78 loss=0.092\n",
      "epoch= 6, batch=  100: sp=0.112 0.132  pair/sec = 10682.20 loss=0.888\n",
      "epoch= 6, batch=  200: sp=0.115 0.133  pair/sec = 10733.95 loss=0.847\n",
      "epoch= 6, batch=  300: sp=0.108 0.128  pair/sec = 10706.48 loss=0.891\n",
      "epoch= 6, batch=  400: sp=0.107 0.127  pair/sec = 10704.87 loss=0.876\n",
      "epoch= 6, batch=  500: sp=0.109 0.123  pair/sec = 10705.05 loss=0.871\n",
      "epoch= 6, batch=  600: sp=0.111 0.124  pair/sec = 10692.77 loss=0.868\n",
      "epoch= 6, batch=  700: sp=0.107 0.122  pair/sec = 10706.05 loss=0.880\n",
      "epoch= 6, batch=  800: sp=0.101 0.125  pair/sec = 10732.14 loss=0.883\n",
      "epoch= 6, batch=  900: sp=0.099 0.122  pair/sec = 10744.13 loss=0.915\n",
      "epoch= 6, batch= 1000: sp=0.104 0.126  pair/sec = 10741.48 loss=0.895\n",
      "epoch= 6, batch= 1100: sp=0.099 0.126  pair/sec = 10700.74 loss=0.872\n",
      "epoch= 6, batch= 1200: sp=0.097 0.122  pair/sec = 10728.66 loss=0.902\n",
      "epoch= 6, batch= 1300: sp=0.095 0.125  pair/sec = 10728.31 loss=0.878\n",
      "epoch= 6, batch= 1400: sp=0.089 0.125  pair/sec = 10695.90 loss=0.885\n",
      "epoch= 6, batch= 1500: sp=0.089 0.124  pair/sec = 10693.28 loss=0.938\n",
      "epoch= 6, batch= 1600: sp=0.091 0.124  pair/sec = 10713.42 loss=0.921\n",
      "\n",
      "epoch= 7, batch=    0: sp=0.090 0.123  pair/sec = 3263.03 loss=0.090\n",
      "epoch= 7, batch=  100: sp=0.090 0.123  pair/sec = 10673.37 loss=0.879\n",
      "epoch= 7, batch=  200: sp=0.085 0.121  pair/sec = 10727.39 loss=0.843\n",
      "epoch= 7, batch=  300: sp=0.083 0.117  pair/sec = 10748.21 loss=0.888\n",
      "epoch= 7, batch=  400: sp=0.083 0.114  pair/sec = 10705.85 loss=0.873\n",
      "epoch= 7, batch=  500: sp=0.086 0.112  pair/sec = 10742.45 loss=0.870\n",
      "epoch= 7, batch=  600: sp=0.090 0.114  pair/sec = 10749.87 loss=0.865\n",
      "epoch= 7, batch=  700: sp=0.087 0.112  pair/sec = 10763.53 loss=0.874\n",
      "epoch= 7, batch=  800: sp=0.083 0.113  pair/sec = 10746.21 loss=0.880\n",
      "epoch= 7, batch=  900: sp=0.079 0.112  pair/sec = 10744.41 loss=0.911\n",
      "epoch= 7, batch= 1000: sp=0.085 0.114  pair/sec = 10754.18 loss=0.890\n",
      "epoch= 7, batch= 1100: sp=0.089 0.116  pair/sec = 10758.27 loss=0.868\n",
      "epoch= 7, batch= 1200: sp=0.090 0.115  pair/sec = 10740.74 loss=0.897\n",
      "epoch= 7, batch= 1300: sp=0.092 0.117  pair/sec = 10719.14 loss=0.875\n",
      "epoch= 7, batch= 1400: sp=0.089 0.118  pair/sec = 10742.29 loss=0.880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 7, batch= 1500: sp=0.089 0.118  pair/sec = 10745.60 loss=0.930\n",
      "epoch= 7, batch= 1600: sp=0.094 0.118  pair/sec = 10753.25 loss=0.912\n",
      "\n",
      "epoch= 8, batch=    0: sp=0.096 0.118  pair/sec = 3269.82 loss=0.088\n",
      "epoch= 8, batch=  100: sp=0.096 0.117  pair/sec = 10702.30 loss=0.869\n",
      "epoch= 8, batch=  200: sp=0.096 0.117  pair/sec = 10751.57 loss=0.836\n",
      "epoch= 8, batch=  300: sp=0.093 0.115  pair/sec = 10746.39 loss=0.886\n",
      "epoch= 8, batch=  400: sp=0.093 0.113  pair/sec = 10737.54 loss=0.872\n",
      "epoch= 8, batch=  500: sp=0.094 0.109  pair/sec = 10690.58 loss=0.868\n",
      "epoch= 8, batch=  600: sp=0.094 0.109  pair/sec = 10693.00 loss=0.860\n",
      "epoch= 8, batch=  700: sp=0.093 0.107  pair/sec = 10747.54 loss=0.869\n",
      "epoch= 8, batch=  800: sp=0.092 0.108  pair/sec = 10741.17 loss=0.880\n",
      "epoch= 8, batch=  900: sp=0.093 0.107  pair/sec = 10752.59 loss=0.907\n",
      "epoch= 8, batch= 1000: sp=0.096 0.108  pair/sec = 10749.00 loss=0.882\n",
      "epoch= 8, batch= 1100: sp=0.096 0.109  pair/sec = 10744.26 loss=0.859\n",
      "epoch= 8, batch= 1200: sp=0.096 0.108  pair/sec = 10746.92 loss=0.892\n",
      "epoch= 8, batch= 1300: sp=0.097 0.108  pair/sec = 10716.51 loss=0.870\n",
      "epoch= 8, batch= 1400: sp=0.096 0.110  pair/sec = 10737.13 loss=0.874\n",
      "epoch= 8, batch= 1500: sp=0.097 0.110  pair/sec = 10750.40 loss=0.920\n",
      "epoch= 8, batch= 1600: sp=0.100 0.110  pair/sec = 10747.64 loss=0.906\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'buffer' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-defeae054d2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mwv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2VecTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset/text8_10.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sgns.vec\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# emb_dim=100, vocab=30000, SparseAdam, lr=0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# wv = Word2VecTrainer(\"dataset/text8.txt\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/SGNS-PyTorch/word2vec/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 pos_u, pos_v, neg_v = self.data.generate_batch(\n\u001b[0m\u001b[1;32m     54\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindows_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_sample_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 )\n",
      "\u001b[0;32m~/code/SGNS-PyTorch/word2vec/data_reader.py\u001b[0m in \u001b[0;36mgenerate_batch\u001b[0;34m(self, window_size, batch_size, neg_sample_num)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mspan\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0mbuffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0mdata_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'buffer' referenced before assignment"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "import pprint\n",
    "import tqdm\n",
    "\n",
    "from word2vec.trainer import Word2VecTrainer\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "wv = Word2VecTrainer(\"dataset/text8_10.txt\", output_file=\"sgns.vec\") # emb_dim=100, vocab=30000, SparseAdam, lr=0.001\n",
    "# wv = Word2VecTrainer(\"dataset/text8.txt\")\n",
    "wv.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T11:38:15.311808Z",
     "start_time": "2021-03-08T11:38:11.018266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab size 50000\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "wv = KeyedVectors.load_word2vec_format(\"sgns.vec\", binary=False)\n",
    "vocab = list(wv.vocab.keys())\n",
    "print(\"Loaded vocab size %i\" % len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T11:38:17.466667Z",
     "start_time": "2021-03-08T11:38:17.290962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5027689131705056\n",
      "0.2358323572771211\n",
      "0.183232016465508\n"
     ]
    }
   ],
   "source": [
    "print(wv.evaluate_word_pairs(datapath('wordsim353.tsv'))[1][0])\n",
    "print(wv.evaluate_word_pairs(\"word2vec/rw/rw_clean.txt\")[1][0])\n",
    "print(wv.evaluate_word_pairs(datapath('simlex999.txt'))[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
