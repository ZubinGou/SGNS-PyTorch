{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T13:36:08.591535Z",
     "start_time": "2021-03-08T13:36:08.583358Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import gensim.downloader as api\n",
    "import pprint\n",
    "import tqdm\n",
    "\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T13:36:09.578435Z",
     "start_time": "2021-03-08T13:36:09.575113Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_wordsim(wordvec):\n",
    "    p_ws353 = wordvec.evaluate_word_pairs(datapath('wordsim353.tsv'))[1][0]\n",
    "    p_rw = wordvec.evaluate_word_pairs(\"word2vec/rw/rw_clean.txt\")[1][0]\n",
    "    p_sl999 = wordvec.evaluate_word_pairs(datapath('simlex999.txt'))[1][0]\n",
    "    print(\"WS353:\", p_ws353)\n",
    "    print(\"RW:\", p_rw)\n",
    "    print(\"SL999\", p_sl999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-08T12:45:57.775Z"
    }
   },
   "source": [
    "## Pretrained GoogleNews-300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T13:20:41.004257Z",
     "start_time": "2021-03-08T13:20:06.626647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab: 3000000\n",
      "vec_dim: 300\n"
     ]
    }
   ],
   "source": [
    "wv_google = KeyedVectors.load_word2vec_format('dataset/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "print(\"vocab:\", len(wv_google.vocab))\n",
    "print(\"vec_dim:\", wv_google.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T13:21:59.029201Z",
     "start_time": "2021-03-08T13:21:57.987236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WS353: 0.6589215888009288\n",
      "RW: 0.5525559901031721\n",
      "SL999 0.43607859778335434\n"
     ]
    }
   ],
   "source": [
    "evaluate_wordsim(wv_google)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T02:34:51.871196Z",
     "start_time": "2021-03-06T02:34:51.858070Z"
    }
   },
   "source": [
    "## Train by gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T11:32:21.828103Z",
     "start_time": "2021-03-08T11:32:18.998738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_records': 1701, 'record_format': 'list of str (tokens)', 'file_size': 33182058, 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/text8/__init__.py', 'license': 'not found', 'description': 'First 100,000,000 bytes of plain text from Wikipedia. Used for testing purposes; see wiki-english-* for proper full Wikipedia datasets.', 'checksum': '68799af40b6bda07dfa47a32612e5364', 'file_name': 'text8.gz', 'read_more': ['http://mattmahoney.net/dc/textdata.html'], 'parts': 1}\n"
     ]
    }
   ],
   "source": [
    "print(api.info(\"text8\"))\n",
    "dataset = api.load(\"text8\")\n",
    "\n",
    "with open(\"dataset/text8.txt\", \"w\") as f:\n",
    "    for data in dataset:\n",
    "        f.write(\" \".join(data) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取text8部分：\n",
    "```sh\n",
    "$ head -i 300 text8.txt > text8_300.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T12:28:26.739730Z",
     "start_time": "2021-03-08T12:27:17.689878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab: 71290\n",
      "vec_dim: 100\n"
     ]
    }
   ],
   "source": [
    "# dataset = open(\"dataset/text8_300.txt\").read()\n",
    "dataset = api.load(\"text8\")\n",
    "model = Word2Vec(dataset)\n",
    "print(\"vocab:\", len(model.wv.vocab))\n",
    "print(\"vec_dim:\", model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T12:33:04.443293Z",
     "start_time": "2021-03-08T12:33:04.012247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.623768051438205\n",
      "0.3198280325425669\n",
      "0.24994655821500755\n"
     ]
    }
   ],
   "source": [
    "evaluate_wordsim(model.wv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train by word2vec DIY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-08T13:47:38.359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "len data: 17005207\n",
      "epoch= 1, batch=    0: sp=0.614 0.369  pair/sec = 91120.71 loss=0.073\n",
      "epoch= 1, batch=10000: sp=0.610 0.366  pair/sec = 10931.75 loss=0.381\n",
      "epoch= 1, batch=20000: sp=0.613 0.366  pair/sec = 10947.02 loss=0.708\n",
      "epoch= 1, batch=30000: sp=0.609 0.368  pair/sec = 10948.62 loss=0.856\n",
      "epoch= 1, batch=40000: sp=0.618 0.370  pair/sec = 11021.52 loss=0.850\n",
      "epoch= 1, batch=50000: sp=0.622 0.374  pair/sec = 9802.78 loss=0.670\n",
      "epoch= 1, batch=60000: sp=0.622 0.373  pair/sec = 10863.37 loss=0.778\n",
      "epoch= 1, batch=70000: sp=0.624 0.376  pair/sec = 11011.65 loss=0.657\n",
      "epoch= 1, batch=80000: sp=0.629 0.379  pair/sec = 10943.09 loss=0.730\n",
      "epoch= 1, batch=90000: sp=0.623 0.382  pair/sec = 10665.93 loss=0.568\n",
      "epoch= 1, batch=100000: sp=0.622 0.381  pair/sec = 9668.13 loss=0.707\n",
      "epoch= 1, batch=110000: sp=0.620 0.385  pair/sec = 10997.14 loss=0.791\n",
      "epoch= 1, batch=120000: sp=0.621 0.388  pair/sec = 10948.56 loss=0.743\n",
      "epoch= 1, batch=130000: sp=0.617 0.389  pair/sec = 10962.46 loss=0.650\n",
      "epoch= 1, batch=140000: sp=0.616 0.387  pair/sec = 10853.96 loss=0.792\n",
      "epoch= 1, batch=150000: sp=0.617 0.393  pair/sec = 9491.06 loss=0.722\n",
      "epoch= 1, batch=160000: sp=0.617 0.395  pair/sec = 10666.19 loss=0.751\n",
      "epoch= 1, batch=170000: sp=0.619 0.396  pair/sec = 10809.44 loss=0.693\n",
      "epoch= 1, batch=180000: sp=0.619 0.396  pair/sec = 10757.78 loss=0.624\n",
      "epoch= 1, batch=190000: sp=0.621 0.397  pair/sec = 10762.67 loss=0.676\n",
      "epoch= 1, batch=200000: sp=0.622 0.398  pair/sec = 9570.95 loss=0.695\n",
      "epoch= 1, batch=210000: sp=0.629 0.399  pair/sec = 10977.68 loss=0.717\n",
      "\n",
      "epoch= 2, batch=    0: sp=0.631 0.398  pair/sec = 91765.56 loss=0.077\n",
      "epoch= 2, batch=10000: sp=0.635 0.401  pair/sec = 10578.39 loss=0.732\n",
      "epoch= 2, batch=20000: sp=0.637 0.403  pair/sec = 10933.05 loss=0.677\n",
      "epoch= 2, batch=30000: sp=0.637 0.403  pair/sec = 10993.21 loss=0.496\n",
      "epoch= 2, batch=40000: sp=0.635 0.402  pair/sec = 10965.48 loss=0.747\n",
      "epoch= 2, batch=50000: sp=0.637 0.401  pair/sec = 9749.48 loss=0.729\n",
      "epoch= 2, batch=60000: sp=0.634 0.399  pair/sec = 10748.01 loss=0.755\n",
      "epoch= 2, batch=70000: sp=0.638 0.401  pair/sec = 10765.16 loss=0.763\n",
      "epoch= 2, batch=80000: sp=0.639 0.402  pair/sec = 10702.73 loss=0.666\n",
      "epoch= 2, batch=90000: sp=0.639 0.400  pair/sec = 10929.50 loss=0.683\n",
      "epoch= 2, batch=100000: sp=0.639 0.398  pair/sec = 9859.26 loss=0.529\n",
      "epoch= 2, batch=110000: sp=0.640 0.399  pair/sec = 11000.12 loss=0.671\n",
      "epoch= 2, batch=120000: sp=0.641 0.399  pair/sec = 10861.99 loss=0.666\n",
      "epoch= 2, batch=130000: sp=0.642 0.399  pair/sec = 10950.50 loss=0.708\n",
      "epoch= 2, batch=140000: sp=0.644 0.398  pair/sec = 10893.25 loss=0.730\n",
      "epoch= 2, batch=150000: sp=0.645 0.401  pair/sec = 9716.51 loss=0.741\n",
      "epoch= 2, batch=160000: sp=0.645 0.402  pair/sec = 10600.14 loss=0.754\n",
      "epoch= 2, batch=170000: sp=0.641 0.403  pair/sec = 10950.56 loss=0.738\n",
      "epoch= 2, batch=180000: sp=0.641 0.403  pair/sec = 11000.89 loss=0.752\n",
      "epoch= 2, batch=190000: sp=0.642 0.406  pair/sec = 10997.12 loss=0.673\n",
      "epoch= 2, batch=200000: sp=0.638 0.405  pair/sec = 9710.42 loss=0.699\n",
      "epoch= 2, batch=210000: sp=0.638 0.405  pair/sec = 10665.89 loss=0.663\n",
      "epoch= 2, batch=220000: sp=0.638 0.406  pair/sec = 10940.30 loss=0.771\n",
      "epoch= 2, batch=230000: sp=0.633 0.407  pair/sec = 10871.00 loss=0.763\n",
      "epoch= 2, batch=240000: sp=0.635 0.408  pair/sec = 10846.60 loss=0.743\n",
      "epoch= 2, batch=250000: sp=0.636 0.409  pair/sec = 9777.09 loss=0.706\n",
      "epoch= 2, batch=260000: sp=0.636 0.407  pair/sec = 10988.26 loss=0.779\n",
      "epoch= 2, batch=270000: sp=0.638 0.410  pair/sec = 10872.69 loss=0.766\n",
      "epoch= 2, batch=280000: sp=0.638 0.410  pair/sec = 10837.28 loss=0.725\n",
      "epoch= 2, batch=290000: sp=0.643 0.410  pair/sec = 10885.61 loss=0.741\n",
      "\n",
      "epoch= 3, batch=    0: sp=0.644 0.410  pair/sec = 92695.30 loss=0.074\n",
      "epoch= 3, batch=10000: sp=0.644 0.412  pair/sec = 10880.96 loss=0.737\n",
      "epoch= 3, batch=20000: sp=0.646 0.414  pair/sec = 10929.24 loss=0.673\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "import pprint\n",
    "import tqdm\n",
    "\n",
    "from word2vec.trainer import Word2VecTrainer\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "wv = Word2VecTrainer(\"dataset/text8.txt\", saved_model_path=\"tmp/skipgram.epoch1.batch50000\", output_file=\"sgns.vec\") # emb_dim=100, vocab=30000, SparseAdam, lr=0.001\n",
    "# wv = Word2VecTrainer(\"dataset/text8.txt\", saved_model_path=\"\", output_file=\"sgns.vec\") # emb_dim=100, vocab=30000, SparseAdam, lr=0.001\n",
    "# wv = Word2VecTrainer(\"dataset/text8_100.txt\", output_file=\"sgns_mini.vec\")\n",
    "wv.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T13:36:01.908312Z",
     "start_time": "2021-03-08T13:35:57.403233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab size 50000\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "wv = KeyedVectors.load_word2vec_format(\"sgns.vec\", binary=False)\n",
    "vocab = list(wv.vocab.keys())\n",
    "print(\"Loaded vocab size %i\" % len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T13:36:11.923946Z",
     "start_time": "2021-03-08T13:36:11.744691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WS353: 0.6060414633359121\n",
      "RW: 0.2730176745649218\n",
      "SL999 0.2319199528849217\n"
     ]
    }
   ],
   "source": [
    "evaluate_wordsim(wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
